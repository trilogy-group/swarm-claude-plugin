# Chat Integration & Voice Commands Specification

## Chat System Architecture

### Integration Options
```typescript
interface ChatIntegration {
  provider: 'langflow' | 'custom' | 'dialogflow' | 'rasa';
  deployment: 'embedded' | 'floating' | 'fullscreen' | 'sidebar';
  authentication: 'shared' | 'separate' | 'anonymous';
  persistence: 'session' | 'localStorage' | 'database';
}
```

## Langflow Integration

### Configuration
```javascript
const langflowConfig = {
  baseUrl: process.env.VITE_LANGFLOW_BASE_URL,
  flowId: process.env.VITE_LANGFLOW_FLOW_ID,
  apiKey: process.env.VITE_LANGFLOW_API_KEY,
  
  widget: {
    position: 'bottom-right',
    trigger: 'bubble', // 'bubble' | 'button' | 'auto'
    theme: 'dark',
    primaryColor: '#3B82F6',
    width: '400px',
    height: '600px'
  },
  
  behavior: {
    autoOpen: false,
    persistState: true,
    welcomeMessage: 'Hello! I can help you manage alerts and analyze network issues.',
    placeholder: 'Type your message or use / for commands...',
    responseDelay: 0
  }
};
```

### Custom Element Implementation
```html
<langflow-chat
  flow-id="{{flowId}}"
  host-url="{{hostUrl}}"
  api-key="{{apiKey}}"
  chat-position="bottom-right"
  chat-trigger="true"
  online-message="AI Assistant Ready"
  placeholder="Ask me about alerts..."
  chat-window-style='{"borderRadius": "12px"}'
/>
```

## Custom Chat Implementation

### Chat Service
```typescript
class ChatService {
  private ws: WebSocket;
  private messageQueue: Message[] = [];
  
  async connect(userId: string): Promise<void> {
    this.ws = new WebSocket(`wss://api.example.com/chat/${userId}`);
    this.setupEventHandlers();
  }
  
  async sendMessage(message: string, context?: ChatContext): Promise<ChatResponse> {
    const payload = {
      message,
      timestamp: new Date().toISOString(),
      context: {
        currentPage: window.location.pathname,
        userRole: context?.userRole,
        activeAlerts: context?.activeAlerts,
        ...context
      }
    };
    
    return this.send('message', payload);
  }
  
  async executeCommand(command: string, params?: any): Promise<CommandResponse> {
    return this.send('command', { command, params });
  }
}
```

## Supported Commands

### Alert Management Commands
```typescript
const alertCommands = {
  '/alerts': {
    description: 'Show active alerts',
    aliases: ['/show-alerts', '/list-alerts'],
    params: {
      severity: 'critical | major | minor | warning',
      timeRange: '1h | 24h | 7d | 30d',
      site: 'siteId'
    },
    example: '/alerts severity:critical timeRange:1h'
  },
  
  '/correlate': {
    description: 'Find correlated alerts',
    aliases: ['/find-patterns'],
    params: {
      alertId: 'string',
      threshold: 'number (0-1)'
    },
    example: '/correlate alertId:ALR-001 threshold:0.8'
  },
  
  '/acknowledge': {
    description: 'Acknowledge an alert',
    aliases: ['/ack'],
    params: {
      alertId: 'string',
      note: 'string'
    },
    example: '/acknowledge alertId:ALR-001 note:"Investigating"'
  },
  
  '/resolve': {
    description: 'Mark alert as resolved',
    params: {
      alertId: 'string',
      resolution: 'string'
    },
    example: '/resolve alertId:ALR-001 resolution:"Power restored"'
  }
};
```

### Analysis Commands
```typescript
const analysisCommands = {
  '/analyze': {
    description: 'Analyze network or alert patterns',
    params: {
      type: 'network | alerts | performance',
      target: 'string',
      depth: 'shallow | deep'
    },
    example: '/analyze type:network target:site-001 depth:deep'
  },
  
  '/rootcause': {
    description: 'Find root cause for an issue',
    aliases: ['/rca'],
    params: {
      alertId: 'string',
      confidence: 'number'
    },
    example: '/rootcause alertId:ALR-001 confidence:0.75'
  },
  
  '/impact': {
    description: 'Assess business impact',
    params: {
      scope: 'alert | site | region',
      id: 'string'
    },
    example: '/impact scope:site id:MSH0031'
  }
};
```

### Navigation Commands
```typescript
const navigationCommands = {
  '/goto': {
    description: 'Navigate to a page',
    aliases: ['/go', '/open'],
    params: {
      page: 'dashboard | alerts | network | remediation'
    },
    example: '/goto page:network'
  },
  
  '/search': {
    description: 'Search across the application',
    params: {
      query: 'string',
      type: 'alerts | sites | users | all'
    },
    example: '/search query:"power failure" type:alerts'
  },
  
  '/filter': {
    description: 'Apply filters to current view',
    params: {
      field: 'string',
      operator: '= | > | < | contains',
      value: 'string'
    },
    example: '/filter field:severity operator:= value:critical'
  }
};
```

## Voice Commands Integration

### Voice Recognition Setup
```typescript
interface VoiceConfig {
  enabled: boolean;
  language: 'en-US' | 'en-GB' | 'es-ES' | 'fr-FR';
  continuous: boolean;
  interimResults: true;
  maxAlternatives: 3;
  
  wakeWord: 'Hey Alert' | 'OK System' | 'Assistant';
  
  commands: {
    trigger: 'voice' | 'push-to-talk' | 'always-on';
    confirmationRequired: boolean;
    feedbackSound: boolean;
  };
}
```

### Voice Command Processing
```typescript
class VoiceProcessor {
  private recognition: SpeechRecognition;
  private synthesis: SpeechSynthesis;
  
  async processVoiceCommand(transcript: string): Promise<VoiceResponse> {
    // Natural language to command mapping
    const command = this.parseNaturalLanguage(transcript);
    
    // Execute command
    const result = await this.executeCommand(command);
    
    // Generate voice response
    const response = this.generateResponse(result);
    
    // Speak response
    if (this.synthesis) {
      this.speak(response.text);
    }
    
    return response;
  }
  
  private parseNaturalLanguage(text: string): Command {
    const patterns = [
      { regex: /show .*? alerts/i, command: '/alerts' },
      { regex: /what.*?root cause/i, command: '/rootcause' },
      { regex: /navigate to (.*)/i, command: '/goto' },
      { regex: /acknowledge alert (.*)/i, command: '/acknowledge' }
    ];
    
    for (const pattern of patterns) {
      if (pattern.regex.test(text)) {
        return this.extractCommand(text, pattern);
      }
    }
    
    return { command: '/help', params: {} };
  }
}
```

### Voice Command Examples
```javascript
const voiceExamples = [
  "Show me critical alerts from the last hour",
  "What's the root cause of alert ALR-001?",
  "Navigate to network analysis",
  "Acknowledge all minor alerts",
  "Show me the status of site MSH0031",
  "What's the current network health score?",
  "Are there any correlated patterns?",
  "Show revenue impact for today"
];
```

## Chat UI Components

### Chat Widget
```typescript
interface ChatWidget {
  // Visual configuration
  appearance: {
    position: 'bottom-right' | 'bottom-left' | 'sidebar';
    size: 'small' | 'medium' | 'large' | 'fullscreen';
    theme: 'light' | 'dark' | 'auto';
    customCSS?: string;
  };
  
  // Behavior
  behavior: {
    minimizable: boolean;
    draggable: boolean;
    resizable: boolean;
    persistPosition: boolean;
    soundEnabled: boolean;
  };
  
  // Features
  features: {
    fileUpload: boolean;
    voiceInput: boolean;
    quickActions: boolean;
    searchHistory: boolean;
    exportChat: boolean;
    codeBlocks: boolean;
    markdown: boolean;
  };
}
```

### Message Types
```typescript
enum MessageType {
  TEXT = 'text',
  COMMAND = 'command',
  CARD = 'card',
  CHART = 'chart',
  TABLE = 'table',
  ACTION = 'action',
  SYSTEM = 'system',
  ERROR = 'error'
}

interface Message {
  id: string;
  type: MessageType;
  sender: 'user' | 'assistant' | 'system';
  content: string | ReactNode;
  timestamp: Date;
  metadata?: {
    confidence?: number;
    source?: string;
    actions?: Action[];
  };
}
```

## Contextual Awareness

### Context Provider
```typescript
class ChatContextProvider {
  getCurrentContext(): ChatContext {
    return {
      // Page context
      currentPage: window.location.pathname,
      pageData: this.extractPageData(),
      
      // User context
      userId: this.auth.getUserId(),
      userRole: this.auth.getUserRole(),
      permissions: this.auth.getPermissions(),
      
      // Application state
      activeAlerts: this.alertService.getActiveCount(),
      selectedItems: this.selection.getSelected(),
      filters: this.filters.getCurrent(),
      
      // Session info
      sessionDuration: this.getSessionDuration(),
      previousActions: this.history.getLast(5)
    };
  }
}
```

## Quick Actions & Suggestions

### Smart Suggestions
```typescript
interface SmartSuggestions {
  triggers: {
    onPageLoad: boolean;
    onError: boolean;
    onIdle: boolean;
    onPattern: boolean;
  };
  
  suggestions: {
    contextual: string[];    // Based on current page
    trending: string[];      // Popular queries
    personal: string[];      // Based on user history
    predictive: string[];    // AI-predicted needs
  };
}
```

### Quick Action Buttons
```javascript
const quickActions = [
  {
    label: 'üö® Critical Alerts',
    action: '/alerts severity:critical',
    tooltip: 'View all critical alerts'
  },
  {
    label: 'üìä Network Status',
    action: '/goto page:network',
    tooltip: 'Open network analysis'
  },
  {
    label: 'üîç Find Root Cause',
    action: '/rootcause',
    tooltip: 'Analyze root causes'
  },
  {
    label: 'üìà Impact Analysis',
    action: '/impact scope:region',
    tooltip: 'Check business impact'
  }
];
```

## Integration with Backend AI

### AI Models Configuration
```typescript
interface AIConfiguration {
  models: {
    nlp: {
      provider: 'openai' | 'anthropic' | 'custom';
      model: 'gpt-4' | 'claude-3' | 'custom-model';
      temperature: number;
      maxTokens: number;
    };
    
    classification: {
      intentRecognition: boolean;
      sentimentAnalysis: boolean;
      entityExtraction: boolean;
    };
    
    generation: {
      responseStyle: 'technical' | 'conversational' | 'concise';
      includeReferences: boolean;
      citeSources: boolean;
    };
  };
}
```

## ‚úÖ Implementation Checklist

### Basic Setup
- [ ] Chat provider selected (Langflow/Custom)
- [ ] API keys and endpoints configured
- [ ] WebSocket connection established
- [ ] Authentication integrated
- [ ] Session management implemented

### UI Implementation
- [ ] Chat widget created
- [ ] Message rendering working
- [ ] Typing indicators
- [ ] Read receipts
- [ ] Timestamp formatting
- [ ] Avatar display

### Command System
- [ ] Command parser implemented
- [ ] All commands registered
- [ ] Parameter validation
- [ ] Error handling
- [ ] Help system
- [ ] Command history

### Voice Integration
- [ ] Speech recognition setup
- [ ] Voice command processing
- [ ] Text-to-speech responses
- [ ] Wake word detection
- [ ] Noise cancellation
- [ ] Multi-language support

### Context & Intelligence
- [ ] Context extraction working
- [ ] Smart suggestions enabled
- [ ] Quick actions configured
- [ ] Learning from interactions
- [ ] Personalization active

### Testing
- [ ] Unit tests for commands
- [ ] Integration tests for chat flow
- [ ] Voice command testing
- [ ] Error scenario testing
- [ ] Performance testing
- [ ] Accessibility testing

## ‚ö° Performance Requirements

| Feature | Target | Maximum |
|---------|--------|---------|
| Message Send | < 100ms | 300ms |
| Response Time | < 2s | 5s |
| Voice Recognition | < 500ms | 1s |
| Command Execution | < 200ms | 500ms |
| Widget Load | < 500ms | 1s |
| History Search | < 100ms | 300ms |

## üìù Developer Guidelines

1. **State Management**: Use separate state for chat to avoid conflicts
2. **Error Recovery**: Implement reconnection logic for WebSocket
3. **Offline Mode**: Queue messages when offline, sync when connected
4. **Security**: Sanitize all user inputs, validate commands server-side
5. **Accessibility**: Ensure screen reader compatibility
6. **Privacy**: Allow users to clear chat history and opt-out of learning

---

*This specification defines the chat and voice command integration. Coordinate with the AI team for model training and with the security team for data handling policies.*
